import pandas as pd

configfile: "config/config.yaml"

URLS = pd.read_csv(config["scenarios"], index_col="Country_Scenario")
SCENARIOS = URLS.index.to_list() 
OUTPUT_FILES = config["minfin_files"]
SOLVER = config["solver"]

def get_url(wildcards):
    return URLS.at[wildcards.scenario, "URL"]

rule all:
    input:
        expand("results/{scenario}/MinFin/{f}.csv", scenario=SCENARIOS, f=OUTPUT_FILES)

rule download_xlsx:
    message:"Downloading xlsm {wildcards.scenario} from Zenodo"
    params:
        url = get_url
    output:
        xlsm = "results/{scenario}/{scenario}.xlsm"
    script: 
        "scripts/download_xlsm.py"

rule extract_data:
    message:"Extracting txt data for {wildcards.scenario}"
    input:
        xlsm = "results/{scenario}/{scenario}.xlsm"
    output:
        txt = "results/{scenario}/{scenario}.txt"
    script: 
        "scripts/extract_data.py"

rule simplify_data:
    message:"Simplifying data for {wildcards.scenario}"
    input:
        txt = "results/{scenario}/{scenario}.txt"
    output:
        txt = "results/{scenario}/{scenario}_simple.txt"
    script: 
        "scripts/simplify.py"

rule preprocess_data:
    message:"Pre-processing data for {wildcards.scenario}"
    params:
        data_format = "momani" # (momani|otoole)
    input:
        txt = "results/{scenario}/{scenario}_simple.txt"
    output:
        txt = "results/{scenario}/{scenario}_preprocessed.txt"
    script: 
        "scripts/preprocess.py"

rule build_model:
    message:"Building LP file for {wildcards.scenario}"
    params:
        model = "resources/osemosys_pp.txt"
    input:
        data = "results/{scenario}/{scenario}_preprocessed.txt"
    output:
        lp = temp("results/{scenario}/{scenario}.lp")
    shell: 
        "glpsol -m {params.model} -d {input.data} --wlp {output.lp} --check"


rule solve_model:
    message:"Solving model for {wildcards.scenario}"
    params:
        solver = SOLVER
    input:
        lp = "results/{scenario}/{scenario}.lp"
    output:
        sol = temp("results/{scenario}/{scenario}.sol")
    shell: 
        """
        if [ {params.solver} = gurobi ]
        then
          gurobi_cl Method=2 ResultFile={output.sol} {input.lp}
        elif [ {params.solver} = cplex ]
        then
          cplex -c "read {input.lp}" "optimize" "write {output.sol}"
        else
          cbc {input.lp} solve -sec 1500 -solu {output.sol}
        fi
        """

rule process_results:
    message:"Processing results for {wildcards.scenario}"
    params:
        otoole_config = "resources/otoole.yaml",
        results_dir = "results/{scenario}/results", 
        solver = SOLVER
    input:
        sol = "results/{scenario}/{scenario}.sol",
        data = "results/{scenario}/{scenario}_simple.txt" # do not use pre-processed! 
    output:
        expand("results/{{scenario}}/results/{csv}.csv", csv=OUTPUT_FILES)
    shell: 
        "otoole results {params.solver} csv {input.sol} {params.results_dir} datafile {input.data} {params.otoole_config}"

"""
This rule may cahnge slightly depending on how you want to extract results 
"""
rule format_results:
    message:"Formating result data for {wildcards.scenario}"
    params:
        minfin_files = expand("{csv}.csv", csv=OUTPUT_FILES),
        in_dir = "results/{scenario}/results/",
        out_dir = "results/{scenario}/MinFin/"
    input:
        expand("results/{{scenario}}/results/{csv}.csv", csv=OUTPUT_FILES)
    output:
        expand("results/{{scenario}}/MinFin/{csv}.csv", csv=OUTPUT_FILES)
    script:
        "scripts/format_results.py"

rule clean:
    shell:
        "rm -r results/*/" # ignore the .gitkeep

rule make_dag:
    shell:
        "snakemake --dag all | dot -Tpdf > dag.pdf"